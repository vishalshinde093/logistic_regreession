install.packages("C:\Users\Vishal\Desktop\rhdfs_1.0.8")
install.packages("C:\\Users\\Vishal\\Desktop\\rhdfs_1.0.8")
install.packages("rJava")
install.packages("rJSONIO")
install.packages("RJSONIO")
install.packages("rmr")
install.packages("rMR")
install.packages("rhdfs")
install.packages("rmr2")
install.packages("rhdfs_1.0.8.tar.gz", repos=NULL, type="source")
install.packages("C:\\Users\\Vishal\\Desktop\\rhdfs_1.0.8.tar.gz", repos=NULL, type="source")
install.packages("C:\\Users\\Vishal\\Desktop\\rhdfs_1.0.8.zip", repos=NULL, type="source")
library(rhdfs)
grep("[au]",c("Harry Potter","Game of thrones","Lord of the rings"))
grep("t.e",c("Harry Potter","Game of thrones","Lord of the rings"))
regexpr("#",c("Harry #Potter","Game of #thrones","Lord of the #rings"))
sub("(Th+)", "e", c("The mountain The", "The hill hill",
"The city without pollution is The peaceful city","Thethe"), perl=TRUE)
sub("(Th+)", "\\1e", c("The mountain", "The hill", "The city without pollution is The peaceful city",
"Thethe"), perl=TRUE)
gsub("(Th+)", "e", c("The mountain The", "The hill hill", "The city without pollution is The peaceful city", "Thethe"), perl=TRUE)
#---------------------------------LDA : TopicModels-------------------------------------------#
library(RTextTools)
library(topicmodels)
library(tm)
data(NYTimes)
data <- NYTimes[sample(1:3100,size=1000,replace=FALSE),]
dim(data)
head(data)
View(data)
#Create a Document Term Matrix
matrix= create_matrix(cbind(as.vector(data$Title),as.vector(data$Subject)),
language="english",removeNumbers=TRUE, removePunctuation=TRUE,
removeSparseTerms=0,
removeStopwords=TRUE, stripWhitespace=TRUE, toLower=TRUE)
inspect(matrix[1:10,1:10])
inspect(matrix[1,1:10])
#Choose number of topics already existing
k <- length(unique(data$Topic.Code))
k
#Divide Data into training and testing
train <- matrix[1:700,]
test <- matrix[701:1000,]
#Building model on train data
train.lda <- LDA(train,k)
get_terms(train.lda,5)
terms(train.lda)
topics(train.lda)
terms(train.lda)
topics(train.lda)
#Get the top topics
train.topics <- topics(train.lda)
#Testing the model
test.topics <- posterior(train.lda,test)
test.topics$topics[1:10,1:5]
test.topics$topics[1:10,1:5]
test.topics <- apply(test.topics$topics, 1, which.max)
#Joining the predicted Topic number to the original test Data
test<-data[701:1000,]
final<-data.frame(Title=test$Title,Subject=test$Subject,Pred_topic=test.topics)
View(final)
#Analysis
table(final$Pred_topic)
View(final[final$Pred_topic==22,])
##--------------------Another method to choose the optimal number of topics ---------#
#------Checking best number of topics--------#
library(topicmodels)
best.model <- lapply(seq(2,10, by=1), function(k){LDA(matrix,k)})
best_model<- as.data.frame(as.matrix(lapply(best.model, logLik)))
final_best_model <- data.frame(topics=c(seq(2,10, by=1)),
log_likelihood=as.numeric(as.matrix(best_model)))
head(final_best_model)
library(ggplot2)
with(final_best_model,qplot(topics,log_likelihood,color="red"))
#Based on the graph, we can choose the best model
k=final_best_model[which.max(final_best_model$log_likelihood),1]
cat("Best topic number is k=",k)
#####Predicting Outcome of Titanic Using GBM & GLMNET
#install.packages("caret",dep=T)
#install.packages("pROC", dep=T)
# load libraries
library(caret)
library(pROC)
#################################################
# data prep
#################################################
# load data
titanicDF <- read.csv("C:/Users/Vishal/Desktop/jigsaw/bagging and boosting/Titanic Case Study/titanicDF.csv")
View(titanicDF)
titanicDF$Title <- ifelse(grepl('Mr ',titanicDF$Name),'Mr',ifelse(grepl('Mrs ',titanicDF$Name),'Mrs',ifelse(grepl('Miss',titanicDF$Name),'Miss','Nothing')))
titanicDF$Age[is.na(titanicDF$Age)] <- median(titanicDF$Age, na.rm=T)
# format
titanicDF <- titanicDF[c('PClass', 'Age',    'Sex',   'Title', 'Survived')]
# dummy variables for factors/characters
titanicDF$Title <- as.factor(titanicDF$Title)
titanicDummy <- dummyVars("~.",data=titanicDF, fullRank=F)
titanicDF <- as.data.frame(predict(titanicDummy,titanicDF))
print(names(titanicDF))
# what is the proportion of your outcome variable?
prop.table(table(titanicDF$Survived))
# save the outcome for the glmnet model
tempOutcome <- titanicDF$Survived
# generalize outcome and predictor variables
outcomeName <- 'Survived'
predictorsNames <- names(titanicDF)[names(titanicDF) != outcomeName]
#################################################
# model it
#################################################
# get names of all caret supported models
names(getModelInfo())
titanicDF$Survived <- ifelse(titanicDF$Survived==1,'yes','nope')
# pick model gbm and find out what type of model it is
getModelInfo()$gbm$type
# split data into training and testing chunks
set.seed(1234)
splitIndex <- createDataPartition(titanicDF[,outcomeName], p = .75, list = FALSE, times = 1)
trainDF <- titanicDF[ splitIndex,]
testDF  <- titanicDF[-splitIndex,]
# create caret trainControl object to control the number of cross-validations performed
objControl <- trainControl(method='cv', number=3, returnResamp='none', summaryFunction = twoClassSummary, classProbs = TRUE)
# run model
objModel <- train(trainDF[,predictorsNames], as.factor(trainDF[,outcomeName]),
method='gbm',
trControl=objControl,
metric = "ROC",
preProc = c("center", "scale"))
# find out variable importance
summary(objModel)
# find out model details
objModel
#################################################
# evalutate model
#################################################
# get predictions on your testing data
# class prediction
predictions <- predict(object=objModel, testDF[,predictorsNames], type='raw')
head(predictions)
postResample(pred=predictions, obs=as.factor(testDF[,outcomeName]))
# probabilities
predictions <- predict(object=objModel, testDF[,predictorsNames], type='prob')
head(predictions)
postResample(pred=predictions[[2]], obs=ifelse(testDF[,outcomeName]=='yes',1,0))
auc <- roc(ifelse(testDF[,outcomeName]=="yes",1,0), predictions[[2]])
print(auc$auc)
################################################
# glmnet model
################################################
# pick model gbm and find out what type of model it is
getModelInfo()$glmnet$type
# save the outcome for the glmnet model
titanicDF$Survived  <- tempOutcome
# split data into training and testing chunks
set.seed(1234)
splitIndex <- createDataPartition(titanicDF[,outcomeName], p = .75, list = FALSE, times = 1)
trainDF <- titanicDF[ splitIndex,]
testDF  <- titanicDF[-splitIndex,]
# create caret trainControl object to control the number of cross-validations performed
objControl <- trainControl(method='cv', number=3, returnResamp='none')
# run model
objModel <- train(trainDF[,predictorsNames], trainDF[,outcomeName], method='glmnet',  metric = "RMSE", trControl=objControl)
# get predictions on your testing data
predictions <- predict(object=objModel, testDF[,predictorsNames])
library(pROC)
auc <- roc(testDF[,outcomeName], predictions)
print(auc$auc)
postResample(pred=predictions, obs=testDF[,outcomeName])
# find out variable importance
summary(objModel)
plot(varImp(objModel,scale=F))
# find out model details
objModel
?RMSE
#install.packages("mlbench", dep=T)
#install.packages("caret", dep=T)
# load libraries
library(mlbench)
library(caret)
?trainControl(method="repeatedcv", number=10, repeats=3)
# load the dataset
data(PimaIndiansDiabetes)
# prepare training scheme
control <- trainControl(method="repeatedcv", number=10, repeats=3)
control
#install.packages("mlbench", dep=T)
#install.packages("caret", dep=T)
# load libraries
library(mlbench)
library(caret)
# load the dataset
data(PimaIndiansDiabetes)
# prepare training scheme
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# CART
set.seed(7)
fit.cart <- train(diabetes~., data=PimaIndiansDiabetes, method="rpart", trControl=control)
# LDA
set.seed(7)
fit.lda <- train(diabetes~., data=PimaIndiansDiabetes, method="lda", trControl=control)
# SVM
set.seed(7)
fit.svm <- train(diabetes~., data=PimaIndiansDiabetes, method="svmRadial", trControl=control)
# kNN
set.seed(7)
fit.knn <- train(diabetes~., data=PimaIndiansDiabetes, method="knn", trControl=control)
# Random Forest
set.seed(7)
fit.rf <- train(diabetes~., data=PimaIndiansDiabetes, method="rf", trControl=control)
#GBM
set.seed(7)
fit.gbm <- train(diabetes~., data=PimaIndiansDiabetes, method="gbm", trControl=control, verbose=FALSE)
# collect resamples
results <- resamples(list(CART=fit.cart, LDA=fit.lda, SVM=fit.svm, KNN=fit.knn, RF=fit.rf,GBM=fit.gbm))
# summarize differences between modes
summary(results)
library(mlbench)
library(caret)
# load the dataset
data(PimaIndiansDiabetes)
# prepare training scheme
control <- trainControl(method="repeatedcv", number=10, repeats=4)
# CART
set.seed(7)
fit.cart <- train(diabetes~., data=PimaIndiansDiabetes, method="rpart", trControl=control)
# LDA
set.seed(7)
fit.lda <- train(diabetes~., data=PimaIndiansDiabetes, method="lda", trControl=control)
# SVM
set.seed(7)
fit.svm <- train(diabetes~., data=PimaIndiansDiabetes, method="svmRadial", trControl=control)
# kNN
set.seed(7)
fit.knn <- train(diabetes~., data=PimaIndiansDiabetes, method="knn", trControl=control)
# Random Forest
set.seed(7)
fit.rf <- train(diabetes~., data=PimaIndiansDiabetes, method="rf", trControl=control)
#GBM
set.seed(7)
fit.gbm <- train(diabetes~., data=PimaIndiansDiabetes, method="gbm", trControl=control, verbose=FALSE)
# collect resamples
results <- resamples(list(CART=fit.cart, LDA=fit.lda, SVM=fit.svm, KNN=fit.knn, RF=fit.rf,GBM=fit.gbm))
# summarize differences between modes
summary(results)
# load libraries
library(mlbench)
library(caret)
# load the dataset
data(PimaIndiansDiabetes)
# prepare training scheme
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# CART
set.seed(7)
fit.cart <- train(diabetes~., data=PimaIndiansDiabetes, method="rpart", trControl=control)
# LDA
set.seed(7)
fit.lda <- train(diabetes~., data=PimaIndiansDiabetes, method="lda", trControl=control)
# SVM
set.seed(7)
fit.svm <- train(diabetes~., data=PimaIndiansDiabetes, method="svmRadial", trControl=control)
# kNN
set.seed(7)
fit.knn <- train(diabetes~., data=PimaIndiansDiabetes, method="knn", trControl=control)
# Random Forest
set.seed(7)
fit.rf <- train(diabetes~., data=PimaIndiansDiabetes, method="rf", trControl=control)
#GBM
set.seed(7)
fit.gbm <- train(diabetes~., data=PimaIndiansDiabetes, method="gbm", trControl=control, verbose=FALSE)
# collect resamples
results <- resamples(list(CART=fit.cart, LDA=fit.lda, SVM=fit.svm, KNN=fit.knn, RF=fit.rf,GBM=fit.gbm))
# summarize differences between modes
summary(results)
?resamples(list(CART=fit.cart, LDA=fit.lda, SVM=fit.svm, KNN=fit.knn, RF=fit.rf,GBM=fit.gbm))
# box and whisker plots to compare models
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results, scales=scales)
# density plots of accuracy
scales <- list(x=list(relation="free"), y=list(relation="free"))
densityplot(results, scales=scales, pch = "|")
# dot plots of accuracy
scales <- list(x=list(relation="free"), y=list(relation="free"))
dotplot(results, scales=scales)
# difference in model predictions
diffs <- diff(results)
# summarize p-values for pair-wise comparisons
summary(diffs)
#---------------------------------LDA : TopicModels-------------------------------------------#
library(RTextTools)
library(topicmodels)
library(tm)
data(NYTimes)
data <- NYTimes[sample(1:3100,size=1000,replace=FALSE),]
dim(data)
head(data)
#Create a Document Term Matrix
matrix= create_matrix(cbind(as.vector(data$Title),as.vector(data$Subject)),
language="english",removeNumbers=TRUE, removePunctuation=TRUE,
removeSparseTerms=0,
removeStopwords=TRUE, stripWhitespace=TRUE, toLower=TRUE)
inspect(matrix[1:10,1:10])
#---------------------------------LDA : TopicModels-------------------------------------------#
library(RTextTools)
library(topicmodels)
library(tm)
data(NYTimes)
data <- NYTimes[sample(1:3100,size=1000,replace=FALSE),]
dim(data)
head(data)
#Create a Document Term Matrix
matrix= create_matrix(cbind(as.vector(data$Title),as.vector(data$Subject)),
language="english",removeNumbers=TRUE, removePunctuation=TRUE,
removeSparseTerms=0,
removeStopwords=TRUE, stripWhitespace=TRUE, toLower=TRUE)
inspect(matrix[1:10,1:10])
#Choose number of topics already existing
k <- length(unique(data$Topic.Code))
k
#Divide Data into training and testing
train <- matrix[1:700,]
test <- matrix[701:1000,]
#Building model on train data
train.lda <- LDA(train,k)
train.lda <- LDA(train,k)
terms(train.lda)
topics(train.lda)
write.csv(data.frame(get_topics(train.lda,27)),"terms_nytimes1.csv",row.names=F)
View(NYTimes)
View(data)
train.topics <- topics(train.lda)
View(data)
View(data)
setwd("C:/Users/Vishal/Desktop/jigsaw/linear regression")
data<-read.csv("DirectMarketing.csv")
library(dplyr)
library(ggplot2)
library(car)
head(data)
##Do exploratory analysis##
plot(data$Age,data$AmountSpent,col="red")
#Combine the Middle and Old levels together
data$Age1<-ifelse(data$Age!="Young","Middle-Old",as.character(data$Age))
data$Age1<-as.factor(data$Age1)
summary(data$Age1)
plot(data$Age1,data$AmountSpent)
#Gender
plot(data$Gender,data$AmountSpent,col="red")
#Own house
summary(data$OwnHome)
plot(data$OwnHome,data$AmountSpent,col="red")
#Married
summary(data$Married)
plot(data$Married,data$AmountSpent,col="red")
#Location
summary(data$Location)
plot(data$Location,data$AmountSpent,col="red")
#Salary
summary(data$Salary)
plot(data$Salary,data$AmountSpent)#Might be heteroescadasticity
#Children
summary(data$Children)
data$Children<-as.factor(data$Children)
plot(data$Children,data$AmountSpent,col="red")
data$Children1<-ifelse(data$Children==3|data$Children==2,"3-2",as.character(data$Children))
data$Children1<-as.factor(data$Children1)
summary(data$Children1)
plot(data$Children1,data$AmountSpent,col="red")
#History
summary(data$History)
#Create a category called missing
data$History1<-ifelse(is.na(data$History),"Missing",as.factor(data$History))
data$History1<-as.factor(data$History1)
summary(data$History1)
data$History1<-factor(data$History1,labels=c("High","Low","Medium","Missing"))
#Catalogues
summary(data$Catalogs)
data1<-data[,-c(1,7,8)]
data1
str(data1)
View(data1)
library(gains)
library(dplyr)
library(irr)
library(caret)
setwd("C:/Users/Vishal/Desktop/jigsaw/logistic regression")
dm<-read.csv("dm.csv")
# Direct Marketer who wants to come up with a process to identify good customers, identify customer id's who are considered good according to his definition
dm%>%mutate(Target=ifelse(AmountSpent>mean(AmountSpent),1,0))->dm
dm%>%select(-AmountSpent)->dm
summary(dm)
#Minimal Data Prep
dm$History1<-ifelse(is.na(dm$History),"Missing",as.character(dm$History))
dm$History1<-as.factor(dm$History1)
summary(dm$History1)
dm$Children<-as.factor(dm$Children)
dm$Catalogs<-as.factor(dm$Catalogs)
dm<-dm[,-8]
str(dm)
View(dm)
